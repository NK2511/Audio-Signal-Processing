{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "943bf10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are all the Important libraries that we need to import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import crepe\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import argrelextrema\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import IPython.display as ipd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from scipy.signal import find_peaks as scipy_find_peaks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2acaab2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Processing new file: Mayamalavagowlai_DevadevaKalayami01__G#3.wav\n",
      "\u001b[1m558/558\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step\n",
      "✅ Done with: Mayamalavagowlai_DevadevaKalayami01__G#3.wav\n",
      "🔧 Processing new file: Mayamalavagowlai_Inthaparaka01__C4.wav\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 34ms/step\n",
      "✅ Done with: Mayamalavagowlai_Inthaparaka01__C4.wav\n",
      "🔧 Processing new file: Mayamalavagowlai_MeruSamana01__C4.wav\n",
      "\u001b[1m641/641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step\n",
      "✅ Done with: Mayamalavagowlai_MeruSamana01__C4.wav\n",
      "🎉 All new files processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import crepe\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "# === SETTINGS ===\n",
    "vocal_folder = \"Vocals_file//Mayamalavagowlai\"  # Your folder with WAV files\n",
    "output_csv = \"Master_Crepe_Mayamalavagowlai.csv\"\n",
    "log_csv = \"Crepe_logMayamalavagowlai.csv\"\n",
    "\n",
    "# === ENSURE LOG FILE EXISTS AND HAS HEADER ===\n",
    "if not os.path.exists(log_csv) or os.path.getsize(log_csv) == 0:\n",
    "    # Create it with correct header\n",
    "    with open(log_csv, \"w\") as f:\n",
    "        f.write(\"AudioPath\\n\")\n",
    "    processed_files = set()\n",
    "else:\n",
    "    processed_files = set(pd.read_csv(log_csv)[\"AudioPath\"].values)\n",
    "\n",
    "# === ENSURE MASTER CSV EXISTS AND HAS HEADER ===\n",
    "if not os.path.exists(output_csv) or os.path.getsize(output_csv) == 0:\n",
    "    with open(output_csv, \"w\") as f:\n",
    "        f.write(\"Index,AudioPath,Raaga,SongName,Tonic,Time,Frequency,Confidence\\n\")\n",
    "    current_song_index = 1 # Initialize for the first song\n",
    "else:\n",
    "    df_existing = pd.read_csv(output_csv)\n",
    "    # Get the max song index if the file is not empty and has an 'Index' column\n",
    "    if not df_existing.empty and 'Index' in df_existing.columns:\n",
    "        current_song_index = df_existing[\"Index\"].max() + 1\n",
    "    else:\n",
    "        current_song_index = 1 # Start from 1 if no existing data or 'Index' column\n",
    "\n",
    "new_log_entries = []\n",
    "\n",
    "# === PROCESS WAV FILES ===\n",
    "for filename in os.listdir(vocal_folder):\n",
    "    if not filename.lower().endswith(\".wav\"):\n",
    "        continue\n",
    "\n",
    "    audio_path = os.path.join(vocal_folder, filename)\n",
    "\n",
    "    if audio_path in processed_files:\n",
    "        print(f\"🟡 Skipping already processed file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"🔧 Processing new file: {filename}\")\n",
    "\n",
    "    # ✅ Extract Raaga, SongName, Tonic\n",
    "    name_without_ext = filename.replace(\".wav\", \"\")\n",
    "    parts = name_without_ext.split(\"_\")\n",
    "\n",
    "    if len(parts) >= 3:\n",
    "        raaga = parts[0]\n",
    "        songname = \"_\".join(parts[1:-1])\n",
    "        tonic = parts[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"Filename not in expected format: {filename}\")\n",
    "\n",
    "    # === Load audio ===\n",
    "    y, sr = librosa.load(audio_path, sr=44100)\n",
    "\n",
    "    # === CREPE pitch estimation ===\n",
    "    time, frequency, confidence, _ = crepe.predict(y, sr, viterbi=True, step_size=20, model_capacity=\"tiny\")\n",
    "\n",
    "    # === Interpolate to STFT time grid ===\n",
    "    spec_time = librosa.times_like(librosa.stft(y), sr=sr)\n",
    "    interp_freq = interp1d(time, frequency, kind='linear', fill_value='extrapolate')\n",
    "    interp_conf = interp1d(time, confidence, kind='linear', fill_value='extrapolate')\n",
    "\n",
    "    new_frequency = interp_freq(spec_time)\n",
    "    new_confidence = interp_conf(spec_time)\n",
    "\n",
    "    # ✅ Remove silent parts by confidence threshold\n",
    "    mask = new_confidence > 0.7  # Adjust threshold as needed\n",
    "    spec_time = spec_time[mask]\n",
    "    new_frequency = new_frequency[mask]\n",
    "    new_confidence = new_confidence[mask]\n",
    "\n",
    "    # === Assign the same song index to all rows of the current song ===\n",
    "    df_single = pd.DataFrame({\n",
    "        \"Index\": [current_song_index]*len(spec_time), # This is the key change\n",
    "        \"AudioPath\": [audio_path]*len(spec_time),\n",
    "        \"Raaga\": [raaga]*len(spec_time),\n",
    "        \"SongName\": [songname]*len(spec_time),\n",
    "        \"Tonic\": [tonic]*len(spec_time),\n",
    "        \"Time\": spec_time,\n",
    "        \"Frequency\": new_frequency,\n",
    "        \"Confidence\": new_confidence\n",
    "    })\n",
    "\n",
    "    df_single.to_csv(output_csv, mode='a', index=False, header=False)\n",
    "    new_log_entries.append(audio_path)\n",
    "    current_song_index += 1 # Increment for the next song\n",
    "    print(f\"✅ Done with: {filename}\")\n",
    "\n",
    "# === UPDATE LOG ===\n",
    "if new_log_entries:\n",
    "    log_df = pd.DataFrame({\"AudioPath\": new_log_entries})\n",
    "    log_df.to_csv(log_csv, mode='a', index=False, header=False)\n",
    "\n",
    "print(\"🎉 All new files processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f1e3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram_with_crepe(spec_time, conf, S_db, sr):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='linear', cmap='viridis')\n",
    "    plt.plot(spec_time, conf, color='r', linewidth=1.5, label='CREPE Pitch')  # Use spec_time\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.ylim(0, 2000)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def find_tonic(S, sr):\n",
    "    chroma = librosa.feature.chroma_stft(S=np.abs(S), sr=sr)\n",
    "    pitch_class_sums = np.sum(np.abs(chroma), axis=1)\n",
    "    pitch_labels = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"]\n",
    "    pitch_class_dict = dict(zip(pitch_labels, pitch_class_sums))\n",
    "    return max(pitch_class_dict, key=pitch_class_dict.get)\n",
    "\n",
    "def get_carnatic_frequencies(tonic):\n",
    "    # Intonational ratios for the basic set of Carnatic notes\n",
    "    carnatic_ratios = {\n",
    "        'sa': 0.5*1.0,    # Tonic (Sa)\n",
    "        'ri1': 0.5*16/15, # Ri1\n",
    "        'ri2': 0.5*9/8,  # Ri2\n",
    "        'ga1': 0.5*6/5,  # Ga1\n",
    "        'ga2': 0.5*5/4, # Ga2\n",
    "        'ma1': 0.5*4/3, # Ma1\n",
    "        'ma2': 0.5*45/32,   # Ma2\n",
    "        'pa': 0.5*3/2,    # Pa\n",
    "        'da1': 0.5*8/5, # Dha1\n",
    "        'da2': 0.5*5/3, # Dha2\n",
    "        'ni1': 0.5*16/9, # Ni1\n",
    "        'ni2': 0.5*15/8,   # Ni2\n",
    "\n",
    "        'Sa': 1.0,    # Tonic (Sa)\n",
    "        'Ri1': 16/15, # Ri1\n",
    "        'Ri2': 9/8,  # Ri2\n",
    "        'Ga1': 6/5,  # Ga1\n",
    "        'Ga2': 5/4, # Ga2\n",
    "        'Ma1': 4/3, # Ma1\n",
    "        'Ma2': 45/32,   # Ma2\n",
    "        'Pa': 3/2,    # Pa\n",
    "        'Da1': 8/5, # Dha1\n",
    "        'Da2': 5/3, # Dha2\n",
    "        'Ni1': 16/9, # Ni1\n",
    "        'Ni2': 15/8,   # Ni2\n",
    "\n",
    "        'SA': 2.0,   # Octave higher (Sa)\n",
    "        'RI1': 2*16/15, # Ri1\n",
    "        'RI2': 2*9/8,  # Ri2\n",
    "        'GA1': 2*6/5,  # Ga1\n",
    "        'GA2': 2*5/4, # Ga2\n",
    "        'MA1': 2*4/3, # Ma1\n",
    "        'MA2': 2*45/32,   # Ma2\n",
    "        'PA': 2*3/2,    # Pa\n",
    "        'DA1': 2*8/5, # Dha1\n",
    "        'DA2': 2*5/3, # Dha2\n",
    "        'NI1': 2*16/9, # Ni1\n",
    "        'NI2': 2*15/8,   \n",
    "    }\n",
    "\n",
    "    tonic_freq = librosa.note_to_hz(tonic)  # Get the frequency of the tonic\n",
    "\n",
    "    # Calculate the frequencies for each Carnatic note relative to the tonic\n",
    "    carnatic_frequencies = {note: tonic_freq * ratio for note, ratio in carnatic_ratios.items()}\n",
    "    return carnatic_frequencies\n",
    "\n",
    "def get_closest_note(freq, carnatic_frequencies):\n",
    "    \"\"\"Find the closest Carnatic note for a given frequency.\"\"\"\n",
    "    return min(carnatic_frequencies, key=lambda note: abs(carnatic_frequencies[note] - freq))\n",
    "\n",
    "def get_closest_frequency(freq, carnatic_frequencies):\n",
    "    \"\"\"Find the closest Carnatic note frequency for a given frequency.\"\"\"\n",
    "    return min(carnatic_frequencies.values(), key=lambda f: abs(f - freq))\n",
    "\n",
    "def get_index_from_time(time_input,conf):\n",
    "    # Define the start and end times\n",
    "    total_duration = end_time - start_time\n",
    "    num_pieces = len(conf)\n",
    "    \n",
    "    # Calculate the duration of each piece\n",
    "    duration_per_piece = total_duration / num_pieces\n",
    "    \n",
    "    # Check if the input time is within the valid range\n",
    "    if time_input < start_time or time_input > end_time:\n",
    "        raise ValueError(f\"Input time must be between {start_time} and {end_time} seconds.\")\n",
    "    \n",
    "    # Calculate the index\n",
    "    index = int((time_input - start_time) / duration_per_piece)\n",
    "    \n",
    "    return index\n",
    "\n",
    "def plot_frequency_with_carnatic_notes(frequency_list, beat_frames, tonic,beat_sr):\n",
    "    beat_frames= librosa.frames_to_time(beat_frames, sr=beat_sr)\n",
    "    loc_extremes = np.where(np.diff(np.sign(np.diff(frequency_list, prepend=np.nan, append=np.nan))) != 0)[0]\n",
    "    extremes = frequency_list[loc_extremes].tolist()\n",
    "    angles = np.degrees(np.arctan(np.diff(frequency_list, prepend=np.nan, append=np.nan) / 2))\n",
    "    # notelist = [(conf[i], i, angles[i], angles[i + 1], i in loc_extremes) for i in range(len(conf) - 1)]\n",
    "    carnatic_frequencies = get_carnatic_frequencies(tonic)\n",
    "    frequency_array = np.array(frequency_list)\n",
    "    \n",
    "    beat_points=[]\n",
    "    for i in beat_frames:\n",
    "        if i < start_time or i > end_time:\n",
    "            continue\n",
    "        beat_points.append(get_index_from_time(i,frequency_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Identify valid (non-NaN) frames\n",
    "    valid_indices = ~np.isnan(frequency_array)  \n",
    "    valid_frequencies = frequency_array[valid_indices]\n",
    "    if len(valid_frequencies) == 0:\n",
    "        raise ValueError(\"No valid frequencies to process.\")\n",
    "\n",
    "    carnatic_frequencies = get_carnatic_frequencies(tonic)\n",
    "\n",
    "    # Plot the graph\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Plot the frequency graph with gaps for NaNs\n",
    "    for start, end in zip(\n",
    "        np.where(np.diff(np.concatenate(([0], valid_indices, [0]))) == 1)[0],\n",
    "        np.where(np.diff(np.concatenate(([0], valid_indices, [0]))) == -1)[0]\n",
    "    ):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=np.arange(start, end),\n",
    "            y=frequency_array[start:end],\n",
    "            mode='lines',\n",
    "            name='Frequency (Hz)',\n",
    "            line=dict(color='blue')\n",
    "        ))\n",
    "\n",
    "    # Plot horizontal lines for Carnatic notes\n",
    "    for note, freq in carnatic_frequencies.items():\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[0, len(frequency_list) - 1],\n",
    "            y=[freq, freq],\n",
    "            mode='lines',\n",
    "            line=dict(dash='dash', color='gray', width=2),\n",
    "            name=note,\n",
    "            hovertemplate=f\"{note} ({freq:.2f} Hz)\"\n",
    "        ))\n",
    "\n",
    "    # Plot the extremes as red dots\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=loc_extremes,\n",
    "        y=extremes,\n",
    "        mode='markers',\n",
    "        marker=dict(color='red', size=2, symbol='circle'),\n",
    "        name='Extremes'\n",
    "    ))\n",
    "\n",
    "    # Plot vertical lines for beat points\n",
    "    for beat in beat_points:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[beat, beat],  # Vertical line at 'beat'\n",
    "            y=[np.nanmin(frequency_array), np.nanmax(frequency_array)],  # Full y-range\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', width=2),\n",
    "            name=f'Beat @ {beat}'\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f'Frequency with Carnatic Notes (Tonic: {tonic})',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Frequency (Hz)',\n",
    "        showlegend=True\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def breaklist(elements, indexes):\n",
    "    segmented_lists = []\n",
    "    start_index = 0  \n",
    "\n",
    "    for idx in indexes:\n",
    "        segment = elements[start_index:idx]\n",
    "        segmented_lists.append(segment)\n",
    "        start_index = idx  \n",
    "    if start_index < len(elements):\n",
    "        segmented_lists.append(elements[start_index:])\n",
    "\n",
    "    return segmented_lists\n",
    "\n",
    "def plot_with_carnatic_bars(note_num, noteslist, carnatic_frequencies):\n",
    "    bars = list(carnatic_frequencies.values())\n",
    "    \n",
    "    # Find relevant frequency range\n",
    "    min_freq = get_closest_frequency(np.nanmin(noteslist[note_num]), carnatic_frequencies)\n",
    "    max_freq = get_closest_frequency(np.nanmax(noteslist[note_num]), carnatic_frequencies)\n",
    "    \n",
    "    # Filter bars within the frequency range\n",
    "    newbars = [i for i in bars if min_freq <= i <= max_freq]\n",
    "    \n",
    "    # Plot\n",
    "    plt.plot(noteslist[note_num])\n",
    "    for i in newbars:\n",
    "        plt.axhline(y=i, color='r', linestyle='--')\n",
    "    plt.show()\n",
    "    for i in newbars:\n",
    "        print(get_closest_note(i, carnatic_frequencies))\n",
    "\n",
    "def spectral_decomp(note, n_clusters, plot=True):\n",
    "    note = np.array(note)\n",
    "    X = np.column_stack((np.arange(len(note)), note))\n",
    "    embedding = SpectralEmbedding(n_components=2, affinity='nearest_neighbors')\n",
    "    X_transformed = embedding.fit_transform(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_transformed)\n",
    "\n",
    "    # Sort clusters based on first occurrence\n",
    "    unique_clusters = np.unique(labels, return_index=True)\n",
    "    sorted_clusters = [cluster for _, cluster in sorted(zip(unique_clusters[1], unique_clusters[0]))]\n",
    "    label_mapping = {old: new for new, old in enumerate(sorted_clusters)}\n",
    "    sorted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "    # Assign frequencies to clusters\n",
    "    segments = [[] for _ in range(n_clusters)]\n",
    "    for idx, freq in enumerate(note):\n",
    "        segments[sorted_labels[idx]].append((idx, freq))\n",
    "\n",
    "    if plot:\n",
    "        fig = go.Figure()\n",
    "\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple', 'cyan', 'magenta']\n",
    "        for i in range(n_clusters):\n",
    "            indices, freqs = zip(*segments[i]) if segments[i] else ([], [])\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=indices,\n",
    "                y=freqs,\n",
    "                mode='markers+lines',\n",
    "                marker=dict(size=6, color=colors[i % len(colors)]),\n",
    "            ))\n",
    "\n",
    "        # Plot horizontal lines at each unique frequency\n",
    "\n",
    "        unique_freqs = [i for i in get_carnatic_frequencies(\"C#3\").values() if min(note) <= i <= max(note)]\n",
    "        unique_notes= [i for i in get_carnatic_frequencies(\"C#3\").keys() if min(note) <= get_carnatic_frequencies(\"C#3\")[i] <= max(note)]\n",
    "        x_values = np.linspace(min(X[:, 0]), max(X[:, 0]), num=100)  # Densely spaced x values\n",
    "\n",
    "        for i in range (len( unique_freqs)):\n",
    "            y_values = np.full_like(x_values,unique_freqs[i])\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=x_values,\n",
    "                y=y_values,\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"gray\", dash=\"dash\"),\n",
    "                showlegend=False,\n",
    "                hovertemplate=f\"{unique_notes[i]}({unique_freqs[i]:.2f} Hz)\"\n",
    "            ))\n",
    "\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "    return [list(zip(*seg))[1] if seg else [] for seg in segments] \n",
    "\n",
    "def playnote(n, beat_audio, beat_sr, beat_times, start_time):\n",
    "    adjusted_beat_times = beat_times - start_time\n",
    "    adjusted_beat_times = adjusted_beat_times[adjusted_beat_times >= 0]  # Remove negative times\n",
    "    if n < 0 or n >= len(adjusted_beat_times) - 1:\n",
    "        print(\"Invalid note index\")\n",
    "        return\n",
    "    note_start_time = adjusted_beat_times[n]\n",
    "    note_end_time = adjusted_beat_times[n+1]\n",
    "    start_sample = int(note_start_time * beat_sr)\n",
    "    end_sample = int(note_end_time * beat_sr)\n",
    "\n",
    "    note_audio = beat_audio[start_sample:end_sample]\n",
    "    ipd.display(ipd.Audio(note_audio, rate=beat_sr))\n",
    "\n",
    "def find_peaks_and_valleys(conf):\n",
    "    peaks = []\n",
    "    valleys = []\n",
    "    \n",
    "    for i in range(1, len(conf) - 1):\n",
    "        if not np.isnan(conf[i-1]) and not np.isnan(conf[i]) and not np.isnan(conf[i+1]):\n",
    "            if conf[i] > conf[i-1] and conf[i] > conf[i+1]:\n",
    "                peaks.append(i)\n",
    "            elif conf[i] < conf[i-1] and conf[i] < conf[i+1]:\n",
    "                valleys.append(i)\n",
    "    \n",
    "    return peaks, valleys\n",
    "\n",
    "def play_segment_between_beats(beat_audio, beat_sr, beat_frames, beat_index,offset=0):\n",
    "    # Ensure the beat_index is valid\n",
    "    if beat_index < 0 or beat_index >= len(beat_frames) - 1:\n",
    "        print(\"Invalid beat index. Please provide a valid index.\")\n",
    "        return\n",
    "\n",
    "    # Get the start and end frames for the segment\n",
    "    start_frame = beat_frames[beat_index-offset]\n",
    "    end_frame = beat_frames[beat_index + 1+offset]\n",
    "\n",
    "    # Convert frames to time\n",
    "    start_time = librosa.frames_to_time(start_frame, sr=beat_sr)\n",
    "    end_time = librosa.frames_to_time(end_frame, sr=beat_sr)\n",
    "\n",
    "    # Convert time to sample indices\n",
    "    start_sample = int(start_time * beat_sr)\n",
    "    end_sample = int(end_time * beat_sr)\n",
    "\n",
    "    # Slice the audio segment\n",
    "    audio_segment = beat_audio[start_sample:end_sample]\n",
    "\n",
    "    # Play the audio segment\n",
    "    ipd.display(ipd.Audio(audio_segment, rate=beat_sr))\n",
    "\n",
    "def trim(data):\n",
    "    data = np.array(data)  \n",
    "    valid_indices = np.where(~np.isnan(data))[0]\n",
    "    valid_data = data[valid_indices]\n",
    "    peaks = argrelextrema(valid_data, np.greater, order=2)[0]\n",
    "\n",
    "    troughs = argrelextrema(valid_data, np.less, order=2)[0]\n",
    "\n",
    "    # Combine peaks & troughs and sort them\n",
    "    extrema = np.sort(np.concatenate((peaks, troughs)))\n",
    "\n",
    "    if len(extrema) < 2:\n",
    "        return data  # Not enough peaks/troughs to trim\n",
    "\n",
    "    # Find start and end positions in original indices\n",
    "    start, end = valid_indices[extrema[0]], valid_indices[extrema[-1]]\n",
    "\n",
    "    return data[start:end+1]\n",
    "\n",
    "def shift_beats_to_peaks_or_valleys(beat_frames, conf):\n",
    "    \"\"\"\n",
    "    Shift the beat frames to align with the nearest peak or valley in the confidence array.\n",
    "    \n",
    "    Parameters:\n",
    "    - beat_frames: The original beat frames.\n",
    "    - conf: The confidence array.\n",
    "    \n",
    "    Returns:\n",
    "    - shifted_beat_frames: The updated beat frames.\n",
    "    \"\"\"\n",
    "    peaks, valleys = find_peaks_and_valleys(conf)\n",
    "    shifted_beat_frames = []\n",
    "\n",
    "    for beat in beat_frames:\n",
    "        # Find the nearest peak or valley\n",
    "        nearest_index = None\n",
    "        min_distance = float('inf')\n",
    "\n",
    "        for index in peaks + valleys:\n",
    "            distance = abs(index - beat)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                nearest_index = index\n",
    "\n",
    "        shifted_beat_frames.append(nearest_index)\n",
    "\n",
    "    return np.array(shifted_beat_frames)\n",
    "\n",
    "def extend_sublists(main_list, num=4):\n",
    "    extended_list = []\n",
    "    for i in range(len(main_list)):\n",
    "        current_sublist = main_list[i]\n",
    "        if i == 0 or i == len(main_list) - 1:\n",
    "            extended_list.append(current_sublist)\n",
    "        else:\n",
    "            new_sublist = []\n",
    "            new_sublist.extend(main_list[i - 1][-num:])\n",
    "            new_sublist.extend(current_sublist)\n",
    "            new_sublist.extend(main_list[i + 1][:num])\n",
    "            extended_list.append(new_sublist)\n",
    "    return extended_list\n",
    "\n",
    "def plot_with_carnatic_bars_with_peaks(segment, carnatic_frequencies, color='lime'):\n",
    "    plt.style.use('dark_background')  # Dark mode\n",
    "\n",
    "    bars = list(carnatic_frequencies.values())\n",
    "\n",
    "    # Find relevant frequency range\n",
    "    min_freq = get_closest_frequency(np.nanmin(segment), carnatic_frequencies)\n",
    "    max_freq = get_closest_frequency(np.nanmax(segment), carnatic_frequencies)\n",
    "    newbars = [i for i in bars if min_freq <= i <= max_freq]\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    x_vals = np.arange(len(segment))\n",
    "    plt.scatter(x_vals, segment, s=8, color=color)\n",
    "\n",
    "    # Peaks and valleys\n",
    "    peaks, _ = scipy_find_peaks(segment)\n",
    "    valleys, _ = scipy_find_peaks(-np.array(segment))\n",
    "    plt.plot(peaks, segment[peaks], \"o\", markersize=4, color=\"cyan\", label=\"Peaks/Valleys\")\n",
    "    plt.plot(valleys, segment[valleys], \"o\", markersize=4, color=\"cyan\")\n",
    "\n",
    "    # Plot Carnatic bars with labels\n",
    "    for freq in newbars:\n",
    "        note = get_closest_note(freq, carnatic_frequencies)\n",
    "        plt.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "        plt.text(0, freq, note, color='orange', fontsize=9, verticalalignment='bottom')\n",
    "\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.title(\"Segment with Peaks, Valleys, and Carnatic Frequency Bars\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "def interpolate_with_nans(data, target_length=128):\n",
    "\n",
    "    data = np.array(data, dtype=np.float64)\n",
    "    original_length = len(data)\n",
    "    x_original = np.linspace(0, 1, original_length)\n",
    "    x_target = np.linspace(0, 1, target_length)\n",
    "    valid = ~np.isnan(data)\n",
    "    if np.count_nonzero(valid) < 2:\n",
    "        return np.full(target_length, np.nan)\n",
    "    interpolator = interp1d(x_original[valid], data[valid], kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "    interpolated = interpolator(x_target)\n",
    "    nan_mask_original = np.isnan(data)\n",
    "    nan_mask_interpolated = np.interp(x_target, x_original, nan_mask_original.astype(float)) > 0.5\n",
    "    interpolated[nan_mask_interpolated] = np.nan\n",
    "    return interpolated\n",
    "\n",
    "def play_segment(beat_audio, beat_sr, start_frame,end_frame):\n",
    "    # Ensure the beat_index is valid\n",
    "\n",
    "\n",
    "    # Convert frames to time\n",
    "    start_time = librosa.frames_to_time(start_frame, sr=beat_sr)\n",
    "    end_time = librosa.frames_to_time(end_frame, sr=beat_sr)\n",
    "\n",
    "    # Convert time to sample indices\n",
    "    start_sample = int(start_time * beat_sr)\n",
    "    end_sample = int(end_time * beat_sr)\n",
    "\n",
    "    # Slice the audio segment\n",
    "    audio_segment = beat_audio[start_sample:end_sample]\n",
    "\n",
    "    # Play the audio segment\n",
    "    ipd.display(ipd.Audio(audio_segment, rate=beat_sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2ff4359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tonic_Normalized_Frequency column added.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This code adds a new column to the Master_Crepe.csv file \n",
    "that normalizes the frequency values based on the tonic of each song.\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Master_Crepe_Mayamalavagowlai.csv\")\n",
    "normalized_values = []\n",
    "for tonic, freq in zip(df[\"Tonic\"], df[\"Frequency\"]):\n",
    "    base = get_carnatic_frequencies(tonic)[\"Sa\"]\n",
    "    if base and base > 0:\n",
    "        normalized_values.append(freq / base)\n",
    "    else:\n",
    "        normalized_values.append(None)  # or np.nan\n",
    "\n",
    "df[\"Tonic_Normalized_Frequency\"] = normalized_values\n",
    "df.to_csv(\"Master_Crepe_Mayamalavagowlai.csv\", index=False)\n",
    "print(\"✅ Tonic_Normalized_Frequency column added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff89270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import Counter, defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json, os\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "MASTER = \"Master_Crepe_Mayamalavagowlai.csv\"\n",
    "CARVA  = \"carva_Mayamalavagowlai.csv\"\n",
    "N_JOBS = os.cpu_count()        # change to e.g. 4 to pin the pool size\n",
    "df_master = pd.read_csv(MASTER)\n",
    "\n",
    "def non_overlapping_segments(conf, window_size, hop_size):\n",
    "    segments = []\n",
    "    indices = []\n",
    "    i = 0\n",
    "    while i < len(conf) - window_size:\n",
    "        segment = conf[i:i + window_size]\n",
    "        if np.isnan(segment).any():\n",
    "            i += hop_size\n",
    "            continue\n",
    "        segments.append(segment)\n",
    "        indices.append(i)\n",
    "        i += window_size  # skip all overlapping windows\n",
    "    return np.array(segments), np.array(indices)\n",
    "\n",
    "def dtw_distance_matrix(segments):\n",
    "    n = len(segments)\n",
    "    dists = np.zeros((n, n))\n",
    "    for i in tqdm(range(n)):\n",
    "        for j in range(i+1, n):\n",
    "            dist, _ = fastdtw(segments[i], segments[j])\n",
    "            dists[i, j] = dist\n",
    "            dists[j, i] = dist\n",
    "    return dists\n",
    "\n",
    "def extract_notes_from_conf(\n",
    "        conf, \n",
    "        initial_window_size, \n",
    "        decay_size, \n",
    "        min_window_size, \n",
    "        outlier_threshold,\n",
    "        similairity_threshold=100):\n",
    "    \"\"\"\n",
    "    Normal clustering of segments with decreasing window size.\n",
    "    \"\"\"\n",
    "    conf = conf.copy()\n",
    "    remaining_conf = conf.copy()\n",
    "    all_removed_segments = []\n",
    "\n",
    "    window_size = initial_window_size\n",
    "    global_label_offset = 0\n",
    "\n",
    "    total_iters = (initial_window_size - min_window_size) // decay_size + 1\n",
    "    iter_count = 0\n",
    "\n",
    "    while window_size >= min_window_size:\n",
    "        iter_count += 1\n",
    "        print(f\"Iteration {iter_count}/{total_iters} — Window Size: {window_size}\")\n",
    "\n",
    "        hop_size = int(window_size / 12)\n",
    "        segments, segment_starts = non_overlapping_segments(remaining_conf, window_size, hop_size)\n",
    "        \n",
    "        if len(segments) == 0:\n",
    "            print(\"  Skipped — no valid segments\")\n",
    "            window_size -= decay_size\n",
    "            continue\n",
    "\n",
    "        dtw_dists = dtw_distance_matrix(segments)\n",
    "\n",
    "        if len(segments) < 2:\n",
    "            return remaining_conf, all_removed_segments  # <-- add this safeguard\n",
    "\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=similairity_threshold,\n",
    "            metric='precomputed',\n",
    "            linkage='average'\n",
    "        )\n",
    "        labels = clustering.fit_predict(dtw_dists)\n",
    "        labels = clustering.fit_predict(dtw_dists)\n",
    "\n",
    "        cluster_dict = defaultdict(list)\n",
    "        cluster_origins = defaultdict(list)\n",
    "\n",
    "        for seg, start_idx, lbl in zip(segments, segment_starts, labels):\n",
    "            cluster_dict[lbl].append(seg)\n",
    "            cluster_origins[lbl].append(start_idx)\n",
    "\n",
    "        clustered = False\n",
    "        for label, starts in cluster_origins.items():\n",
    "            if len(starts) >= outlier_threshold:\n",
    "                clustered = True\n",
    "                global_label = global_label_offset + label\n",
    "                for i in starts:\n",
    "                    remaining_conf[i:i + window_size] = np.full(window_size, np.nan)\n",
    "                    all_removed_segments.append([i, i + window_size, global_label])\n",
    "\n",
    "        if clustered:\n",
    "            print(f\"  Clusters found: {len(set(labels))}, removed some segments.\")\n",
    "        else:\n",
    "            print(f\"  Clusters found: {len(set(labels))}, but none met the threshold.\")\n",
    "\n",
    "        global_label_offset += len(set(labels))\n",
    "        window_size -= decay_size\n",
    "\n",
    "    return remaining_conf, all_removed_segments\n",
    "\n",
    "def extract_notes_from_conf_pca(conf,\n",
    "    initial_window_size = 128,\n",
    "    decay_size = 8,\n",
    "    min_window_size = 32,\n",
    "    hop_factor = 12,\n",
    "    outlier_threshold = 3,\n",
    "    similarity_threshold = 0.7,\n",
    "    pca_components = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    PCA-based clustering of segments with decreasing window size.\n",
    "    \"\"\"\n",
    "    conf = conf.copy()\n",
    "    remaining_conf = conf.copy()\n",
    "    all_removed_segments = []\n",
    "    global_label_offset = 0\n",
    "\n",
    "    window_size = initial_window_size\n",
    "    total_iters = (initial_window_size - min_window_size) // decay_size + 1\n",
    "    iter_count = 0\n",
    "\n",
    "    while window_size >= min_window_size:\n",
    "        iter_count += 1\n",
    "        print(f\"Iteration {iter_count}/{total_iters} — Window Size: {window_size}\")\n",
    "\n",
    "        hop_size = max(1, int(window_size / hop_factor))\n",
    "        segments, segment_starts = non_overlapping_segments(remaining_conf, window_size, hop_size)\n",
    "\n",
    "        if len(segments) < 2:\n",
    "            print(\"  Skipped — not enough segments.\")\n",
    "            window_size -= decay_size\n",
    "            continue\n",
    "\n",
    "        # === PCA transformation ===\n",
    "        X_abs = np.stack(segments)\n",
    "        X_shape = X_abs - np.mean(X_abs, axis=1, keepdims=True)\n",
    "        X_combined = np.concatenate([X_abs, X_shape], axis=1)\n",
    "\n",
    "        pca = PCA(n_components=min(pca_components, X_combined.shape[1]))\n",
    "        X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "        dist_matrix = squareform(pdist(X_pca, metric='euclidean'))\n",
    "\n",
    "        # === Clustering ===\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=similarity_threshold,\n",
    "            metric='precomputed',\n",
    "            linkage='average'\n",
    "        )\n",
    "        labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "        cluster_origins = defaultdict(list)\n",
    "        for start_idx, lbl in zip(segment_starts, labels):\n",
    "            cluster_origins[lbl].append(start_idx)\n",
    "\n",
    "        clustered = False\n",
    "        for label, starts in cluster_origins.items():\n",
    "            if len(starts) >= outlier_threshold:\n",
    "                clustered = True\n",
    "                global_label = global_label_offset + label\n",
    "                for i in starts:\n",
    "                    remaining_conf[i:i + window_size] = np.full(window_size, np.nan)\n",
    "                    all_removed_segments.append([i, i + window_size, global_label])\n",
    "\n",
    "        if clustered:\n",
    "            print(f\"  Clusters found: {len(set(labels))}, removed segments.\")\n",
    "        else:\n",
    "            print(f\"  Clusters found: {len(set(labels))}, but none met the threshold.\")\n",
    "\n",
    "        global_label_offset += len(set(labels))\n",
    "        window_size -= decay_size\n",
    "\n",
    "    return remaining_conf, all_removed_segments\n",
    "\n",
    "def plot_colored_segments(original_conf, removed_segments, residual_conf=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import matplotlib.colors as mcolors\n",
    "\n",
    "    # Assign a color to each cluster\n",
    "    cluster_labels = sorted(set(lbl for _, _, lbl in removed_segments))\n",
    "    cmap = cm.get_cmap('tab20', len(cluster_labels))\n",
    "    cluster_to_color = {label: cmap(i) for i, label in enumerate(cluster_labels)}\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(original_conf, label=\"Original\", alpha=0.2, color='gray')\n",
    "\n",
    "    # Plot segments grouped by cluster label\n",
    "    for start, end, label in removed_segments:\n",
    "        plt.plot(range(start, end), original_conf[start:end], color=cluster_to_color[label], label=f\"Cluster {label}\")\n",
    "\n",
    "    # Plot residual if given\n",
    "    if residual_conf is not None:\n",
    "        plt.plot(residual_conf, label=\"Residual\", linewidth=2, color='black')\n",
    "\n",
    "    # Create a legend without duplicate labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.title(\"Clusters of Repeating Notes\")\n",
    "    plt.xlabel(\"Time Index\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def remap_cluster_labels(removed_segments):\n",
    "    old_labels = sorted(set(lbl for _, _, lbl in removed_segments))\n",
    "    label_map  = {old: new for new, old in enumerate(old_labels)}\n",
    "    return [(s, e, label_map[lbl]) for s, e, lbl in removed_segments]\n",
    "\n",
    "def process_one_song(song_idx):\n",
    "    \"\"\"Worker: returns a list[dict] for one song.\"\"\"\n",
    "    song_df   = df_master[df_master[\"Index\"] == song_idx].reset_index(drop=True)\n",
    "    audio_path = song_df.loc[0, \"AudioPath\"]\n",
    "    tonic_norm = song_df[\"Tonic_Normalized_Frequency\"].values\n",
    "\n",
    "    residual_conf, removed_segments_local = extract_notes_from_conf(\n",
    "        tonic_norm,\n",
    "        initial_window_size = 60,\n",
    "        decay_size          = 2,\n",
    "        min_window_size     = 15,\n",
    "        outlier_threshold   = 2,\n",
    "        similairity_threshold = 0.5\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for start, end, lbl in remap_cluster_labels(removed_segments_local):\n",
    "        rows.append({\n",
    "            \"Index\"      : int(song_idx),\n",
    "            \"AudioPath\"  : audio_path,\n",
    "            \"SegmentList\": json.dumps(tonic_norm[start:end].tolist()),\n",
    "            \"StartFrame\" : int(start),\n",
    "            \"EndFrame\"   : int(end - 1),\n",
    "            \"Label\"      : lbl\n",
    "        })\n",
    "    return rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdc595",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram_with_crepe()\n",
    "\n",
    "# \"\"\"This code here is just to see if the DTW is working or not, you can ignore this part, it is just for testing purposes\"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # 1️⃣ Load Master file\n",
    "# df_master = pd.read_csv(\"Master_Crepe_Mayamalavagowlai.csv\")\n",
    "\n",
    "# # 2️⃣ Get the first song's index (lowest Index)\n",
    "# song_idx = df_master[\"Index\"].min()+3\n",
    "\n",
    "# # 3️⃣ Filter rows for this song & take first 1000 rows\n",
    "# first_song_df = df_master[df_master[\"Index\"] == song_idx].head(4000).reset_index(drop=True)\n",
    "\n",
    "# # 4️⃣ Extract the frequency contour\n",
    "# tonic_norm = first_song_df[\"Tonic_Normalized_Frequency\"].values\n",
    "\n",
    "# # 5️⃣ Run your extraction\n",
    "# residual_conf, removed_segments_local = extract_notes_from_conf_pca(\n",
    "#     tonic_norm,\n",
    "#     initial_window_size = 60,\n",
    "#     decay_size          = 2,\n",
    "#     min_window_size     = 15,\n",
    "#     hop_factor= 12,\n",
    "#     outlier_threshold   = 2,\n",
    "#     similarity_threshold = 0.4,\n",
    "#     pca_components= 4\n",
    "# )\n",
    "\n",
    "\n",
    "# # 6️⃣ Remap labels for neat coloring\n",
    "# removed_segments_local = remap_cluster_labels(removed_segments_local)\n",
    "\n",
    "# # 7️⃣ Plot\n",
    "# plot_colored_segments(\n",
    "#     original_conf = tonic_norm,\n",
    "#     removed_segments = removed_segments_local,#REmoved segments local has a list of tuples (start, end, label)\n",
    "#     residual_conf = residual_conf\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" This code is to play the segments of the song that were removed by the DTW algorithm.\n",
    "# This is useful to listen to the segments that were clustered together and removed from the original frequency contour.\"\"\"\n",
    "\n",
    "# import pandas as pd\n",
    "# import librosa\n",
    "# import IPython.display as ipd\n",
    "\n",
    "# def play_segment(csvfile, audio_index, sr, start_idx, end_idx):\n",
    "#     df = pd.read_csv(csvfile)\n",
    "#     audio_path = df.loc[df['Index'] == audio_index, 'AudioPath'].values[0]\n",
    "\n",
    "#     # For this song, get the original spec_time (after confidence filter)\n",
    "#     spec_time = df[df['Index'] == audio_index][\"Time\"].values\n",
    "\n",
    "#     # Map indices to real time\n",
    "#     start_time = spec_time[start_idx]\n",
    "#     end_time   = spec_time[end_idx]\n",
    "\n",
    "#     audio = librosa.load(audio_path, sr=sr)[0]\n",
    "\n",
    "#     start_sample = int(start_time * sr)\n",
    "#     end_sample   = int(end_time * sr)\n",
    "\n",
    "#     return ipd.Audio(audio[start_sample:end_sample], rate=sr)\n",
    "\n",
    "\n",
    "\n",
    "# # Suppose removed_segments_local is given\n",
    "# # Example: [(start, end, cluster)]\n",
    "\n",
    "# # Compute unique clusters safely\n",
    "# clusters = sorted(set(seg[2] for seg in removed_segments_local))\n",
    "# for cluster_id in clusters:\n",
    "#     print(f\"=== Playing Cluster {cluster_id} ===\")\n",
    "#     for segment in removed_segments_local:\n",
    "#         if segment[2] == cluster_id:\n",
    "#             display(\n",
    "#                 play_segment(\n",
    "#                     'Master_Crepe_Mayamalavagowlai.csv',\n",
    "#                     audio_index=song_idx,\n",
    "#                     sr=44100,\n",
    "#                     start_idx=segment[0],\n",
    "#                     end_idx=segment[1]\n",
    "#                 )\n",
    "#             )\n",
    "#     print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa319c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 330.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py\", line 413, in get_loc\n    return self._range.index(new_key)\nValueError: 0 is not in range\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\nandh\\AppData\\Local\\Temp\\ipykernel_11008\\1339505839.py\", line 82, in process_one_song_pca\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py\", line 1183, in __getitem__\n    return self.obj._get_value(*key, takeable=self._takeable)\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\", line 4221, in _get_value\n    row = self.index.get_loc(index)\n  File \"c:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py\", line 415, in get_loc\n    raise KeyError(key) from err\nKeyError: 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 114\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# ------------- parallel map -------------\u001b[39;00m\n\u001b[0;32m    112\u001b[0m song_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(df_master[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m--> 114\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_JOBS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloky\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_one_song_pca\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msong_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# flatten list‑of‑lists -> list‑of‑dicts\u001b[39;00m\n\u001b[0;32m    119\u001b[0m flat_rows \u001b[38;5;241m=\u001b[39m [row \u001b[38;5;28;01mfor\u001b[39;00m song_rows \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m song_rows]\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "\"\"\" This code here is the MAIN PART of the script that processes all songs in parallel and saves the results to a CSV file.\"\"\"\n",
    "\n",
    "\n",
    "def extract_notes_from_conf_pca(conf,\n",
    "    initial_window_size = 128,\n",
    "    decay_size = 8,\n",
    "    min_window_size = 32,\n",
    "    hop_factor = 12,\n",
    "    outlier_threshold = 3,\n",
    "    similarity_threshold = 0.04,\n",
    "    pca_components = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    PCA-based clustering of segments with decreasing window size.\n",
    "    \"\"\"\n",
    "    conf = conf.copy()\n",
    "    remaining_conf = conf.copy()\n",
    "    all_removed_segments = []\n",
    "    global_label_offset = 0\n",
    "\n",
    "    window_size = initial_window_size\n",
    "    total_iters = (initial_window_size - min_window_size) // decay_size + 1\n",
    "    iter_count = 0\n",
    "\n",
    "    while window_size >= min_window_size:\n",
    "        iter_count += 1\n",
    "        print(f\"Iteration {iter_count}/{total_iters} — Window Size: {window_size}\")\n",
    "\n",
    "        hop_size = max(1, int(window_size / hop_factor))\n",
    "        segments, segment_starts = non_overlapping_segments(remaining_conf, window_size, hop_size)\n",
    "\n",
    "        if len(segments) < 2:\n",
    "            print(\"  Skipped — not enough segments.\")\n",
    "            window_size -= decay_size\n",
    "            continue\n",
    "\n",
    "        # === PCA transformation ===\n",
    "        X_abs = np.stack(segments)\n",
    "        X_shape = X_abs - np.mean(X_abs, axis=1, keepdims=True)\n",
    "        X_combined = np.concatenate([X_abs, X_shape], axis=1)\n",
    "\n",
    "        pca = PCA(n_components=min(pca_components, X_combined.shape[1]))\n",
    "        X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "        dist_matrix = squareform(pdist(X_pca, metric='euclidean'))\n",
    "\n",
    "        # === Clustering ===\n",
    "        clustering = AgglomerativeClustering(\n",
    "            n_clusters=None,\n",
    "            distance_threshold=similarity_threshold,\n",
    "            metric='precomputed',\n",
    "            linkage='average'\n",
    "        )\n",
    "        labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "        cluster_origins = defaultdict(list)\n",
    "        for start_idx, lbl in zip(segment_starts, labels):\n",
    "            cluster_origins[lbl].append(start_idx)\n",
    "\n",
    "        clustered = False\n",
    "        for label, starts in cluster_origins.items():\n",
    "            if len(starts) >= outlier_threshold:\n",
    "                clustered = True\n",
    "                global_label = global_label_offset + label\n",
    "                for i in starts:\n",
    "                    remaining_conf[i:i + window_size] = np.full(window_size, np.nan)\n",
    "                    all_removed_segments.append([i, i + window_size, global_label])\n",
    "\n",
    "        if clustered:\n",
    "            print(f\"  Clusters found: {len(set(labels))}, removed segments.\")\n",
    "        else:\n",
    "            print(f\"  Clusters found: {len(set(labels))}, but none met the threshold.\")\n",
    "\n",
    "        global_label_offset += len(set(labels))\n",
    "        window_size -= decay_size\n",
    "\n",
    "    return remaining_conf, all_removed_segments\n",
    "\n",
    "def process_one_song_pca(song_idx):\n",
    "    \"\"\"Worker: returns a list[dict] for one song.\"\"\"\n",
    "    song_df   = df_master[df_master[\"Index\"] == song_idx].reset_index(drop=True)\n",
    "    audio_path = song_df.loc[0, \"AudioPath\"]\n",
    "    tonic_norm = song_df[\"Tonic_Normalized_Frequency\"].values\n",
    "\n",
    "    residual_conf, removed_segments_local = extract_notes_from_conf_pca(\n",
    "    tonic_norm,\n",
    "    initial_window_size = 60,\n",
    "    decay_size          = 2,\n",
    "    min_window_size     = 15,\n",
    "    hop_factor= 12,\n",
    "    outlier_threshold   = 2,\n",
    "    similarity_threshold = 0.04,\n",
    "    pca_components= 15\n",
    ")\n",
    "\n",
    "    rows = []\n",
    "    for start, end, lbl in remap_cluster_labels(removed_segments_local):\n",
    "        rows.append({\n",
    "            \"Index\"      : int(song_idx),\n",
    "            \"AudioPath\"  : audio_path,\n",
    "            \"SegmentList\": json.dumps(tonic_norm[start:end].tolist()),\n",
    "            \"StartFrame\" : int(start),\n",
    "            \"EndFrame\"   : int(end - 1),\n",
    "            \"Label\"      : lbl\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------- parallel map -------------\n",
    "song_indices = sorted(df_master[\"Index\"].unique())\n",
    "\n",
    "results = Parallel(n_jobs=N_JOBS, backend=\"loky\")(\n",
    "            delayed(process_one_song_pca)(idx) for idx in tqdm(song_indices)\n",
    "          )\n",
    "\n",
    "# flatten list‑of‑lists -> list‑of‑dicts\n",
    "flat_rows = [row for song_rows in results for row in song_rows]\n",
    "carva_df  = pd.DataFrame(flat_rows)\n",
    "\n",
    "# ------------- write / append -------------\n",
    "if Path(CARVA).exists():\n",
    "    carva_df.to_csv(CARVA, mode=\"a\", index=False, header=False)\n",
    "else:\n",
    "    carva_df.to_csv(CARVA, index=False)\n",
    "\n",
    "print(f\"✅ Parallel run finished — {len(carva_df)} segments across {len(song_indices)} songs saved to {CARVA}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3dbd49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in CSV: 1762\n",
      "Valid segments used: 1762\n",
      "Total length of signal: 88100\n",
      "Window size: 50, hop size: 50\n",
      "Expected segments: 1762\n",
      "Clusters found: 12. Removed 1754 segments.\n",
      "Number of labels: 1762\n",
      "Updated carva_Mayamalavagowlai.csv with Second Labels.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert Interpolated_SegmentList, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18096\\1619622984.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0minterpolated\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;31m# Insert new column after \"SegmentList\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[0msegment_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SegmentList\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Interpolated_SegmentList\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;31m# Save to CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   5154\u001b[0m                 \u001b[1;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5155\u001b[0m             )\n\u001b[0;32m   5156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5157\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5158\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5160\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loc must be int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5161\u001b[0m         \u001b[1;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert Interpolated_SegmentList, already exists"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "\n",
    "# --------- Utility Functions ---------\n",
    "\n",
    "def interpolate_list(lst, target_len):\n",
    "    original_len = len(lst)\n",
    "    if original_len == 0:\n",
    "        return [0] * target_len\n",
    "    return list(np.interp(np.linspace(0, original_len - 1, target_len),\n",
    "                          np.arange(original_len), lst))\n",
    "\n",
    "def non_overlapping_segments(arr, window_size, hop_size):\n",
    "    segments = []\n",
    "    starts = []\n",
    "    for start in range(0, len(arr) - window_size + 1, hop_size):\n",
    "        segment = arr[start:start + window_size]\n",
    "        if not np.any(np.isnan(segment)):\n",
    "            segments.append(segment)\n",
    "            starts.append(start)\n",
    "    return segments, starts\n",
    "\n",
    "# --------- Main Clustering Function ---------\n",
    "\n",
    "def extract_notes_from_conf_once_pca(conf, window_size=128, hop_size=128,\n",
    "                                     outlier_threshold=3, similarity_threshold=0.7,\n",
    "                                     pca_components=10):\n",
    "    conf = conf.copy()\n",
    "    remaining_conf = conf.copy()\n",
    "    all_removed_segments = []\n",
    "\n",
    "    segments, segment_starts = non_overlapping_segments(remaining_conf, window_size, hop_size)\n",
    "\n",
    "    if len(segments) < 2:\n",
    "        print(\"Not enough segments to compare.\")\n",
    "        return remaining_conf, all_removed_segments, []\n",
    "\n",
    "    X_abs = np.stack(segments)\n",
    "    X_shape = X_abs - np.mean(X_abs, axis=1, keepdims=True)\n",
    "    X_combined = np.concatenate([X_abs, X_shape], axis=1)\n",
    "\n",
    "    pca = PCA(n_components=min(pca_components, X_combined.shape[1]))\n",
    "    X_pca = pca.fit_transform(X_combined)\n",
    "\n",
    "    dist_matrix = squareform(pdist(X_pca, metric='euclidean'))\n",
    "\n",
    "    clustering = AgglomerativeClustering(\n",
    "        n_clusters=None,\n",
    "        distance_threshold=similarity_threshold,\n",
    "        metric='precomputed',\n",
    "        linkage='average'\n",
    "    )\n",
    "    labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "    cluster_origins = defaultdict(list)\n",
    "    for start_idx, lbl in zip(segment_starts, labels):\n",
    "        cluster_origins[lbl].append(start_idx)\n",
    "\n",
    "    for label, starts in cluster_origins.items():\n",
    "        if len(starts) >= outlier_threshold:\n",
    "            for i in starts:\n",
    "                remaining_conf[i:i + window_size] = np.full(window_size, np.nan)\n",
    "                all_removed_segments.append([i, i + window_size, label])\n",
    "\n",
    "    print(f\"Clusters found: {len(set(labels))}. Removed {len(all_removed_segments)} segments.\")\n",
    "    return remaining_conf, all_removed_segments, labels\n",
    "\n",
    "# --------- CSV Update Function ---------\n",
    "\n",
    "def update_carva_csv_with_labels(file_path, labels):\n",
    "    carva_df = pd.read_csv(file_path)\n",
    "\n",
    "    if len(labels) != len(carva_df):\n",
    "        raise ValueError(f\"Label count ({len(labels)}) does not match row count ({len(carva_df)})\")\n",
    "\n",
    "    carva_df['Second Labels'] = labels\n",
    "    carva_df.to_csv(file_path, index=False)\n",
    "    print(f\"Updated {file_path} with Second Labels.\")\n",
    "\n",
    "# --------- Main Driver Code ---------\n",
    "\n",
    "file_path = 'carva_Mayamalavagowlai.csv'\n",
    "second_phase_segments = []\n",
    "second_queue = []\n",
    "\n",
    "carva_df = pd.read_csv(file_path)\n",
    "segments = carva_df['SegmentList']\n",
    "\n",
    "for segment in segments:\n",
    "    if pd.isna(segment):\n",
    "        continue  # skip blank entries\n",
    "    try:\n",
    "        seg = ast.literal_eval(segment)\n",
    "    except:\n",
    "        continue  # skip invalid entries\n",
    "    interp = interpolate_list(seg, 50)\n",
    "    second_phase_segments.append(interp)\n",
    "    second_queue += interp  # extend the full signal queue\n",
    "\n",
    "# --------- Debug Info ---------\n",
    "print(\"Total rows in CSV:\", len(carva_df))\n",
    "print(\"Valid segments used:\", len(second_phase_segments))\n",
    "print(\"Total length of signal:\", len(second_queue))\n",
    "print(\"Window size: 50, hop size: 50\")\n",
    "print(\"Expected segments:\", len(second_queue) // 50)\n",
    "\n",
    "# --------- Run Clustering ---------\n",
    "_, _, labels = extract_notes_from_conf_once_pca(second_queue, 50, 50)\n",
    "\n",
    "print(\"Number of labels:\", len(labels))\n",
    "\n",
    "# --------- Update CSV ---------\n",
    "update_carva_csv_with_labels(file_path, labels)\n",
    "file_path = 'carva_Mayamalavagowlai.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Compute interpolated segments\n",
    "interpolated = []\n",
    "for val in df[\"SegmentList\"]:\n",
    "    try:\n",
    "        segment = ast.literal_eval(val)\n",
    "        interpolated.append(interpolate_list(segment, 50))\n",
    "    except:\n",
    "        interpolated.append([])\n",
    "\n",
    "# Insert new column after \"SegmentList\"\n",
    "segment_index = df.columns.get_loc(\"SegmentList\")\n",
    "df.insert(segment_index + 1, \"Interpolated_SegmentList\", interpolated)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(file_path, index=False)\n",
    "print(\"✅ Interpolated_SegmentList column added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c3747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎼 Plotting interpolated segments (overlapping) for Cluster 1...\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n",
      "Skipping segment due to error: expected string or bytes-like object\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎧 Playing Cluster 1 ===\n",
      "\n",
      "📄 AudioPath: Vocals_file//Mayamalavagowlai\\Mayamalavagowlai_DevadevaKalayami01__G#3.wav\n",
      "🎵 Swara: Not labeled\n",
      "⚠️ Could not load audio: zero-size array to reduction operation maximum which has no identity\n",
      "\n",
      "📄 AudioPath: Vocals_file//Mayamalavagowlai\\Mayamalavagowlai_DevadevaKalayami01__G#3.wav\n",
      "🎵 Swara: Not labeled\n",
      "⚠️ Could not load audio: zero-size array to reduction operation maximum which has no identity\n",
      "\n",
      "📄 AudioPath: Vocals_file//Mayamalavagowlai\\Mayamalavagowlai_DevadevaKalayami01__G#3.wav\n",
      "🎵 Swara: Not labeled\n",
      "⚠️ Could not load audio: zero-size array to reduction operation maximum which has no identity\n",
      "\n",
      "📄 AudioPath: Vocals_file//Mayamalavagowlai\\Mayamalavagowlai_DevadevaKalayami01__G#3.wav\n",
      "🎵 Swara: Not labeled\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 208\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-----------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    167\u001b[0m carnatic_ratios \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msa\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.0\u001b[39m,    \u001b[38;5;66;03m# Tonic (Sa)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mri1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m16\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m15\u001b[39m, \u001b[38;5;66;03m# Ri1\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNI2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m15\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m8\u001b[39m,   \n\u001b[0;32m    206\u001b[0m }\n\u001b[1;32m--> 208\u001b[0m \u001b[43mplay_specific_second_phase_cluster\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcarnatic_frequencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcarnatic_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcarva_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcarva_Mayamalavagowlai.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaster_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMaster_Crepe_Mayamalavagowlai.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m44100\u001b[39;49m\n\u001b[0;32m    214\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 155\u001b[0m, in \u001b[0;36mplay_specific_second_phase_cluster\u001b[1;34m(carva_csv, master_csv, cluster_number, carnatic_frequencies, sr)\u001b[0m\n\u001b[0;32m    152\u001b[0m end_time   \u001b[38;5;241m=\u001b[39m spec_time[end_idx] \u001b[38;5;28;01mif\u001b[39;00m end_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(spec_time) \u001b[38;5;28;01melse\u001b[39;00m spec_time[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     audio, _ \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m     start_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(start_time \u001b[38;5;241m*\u001b[39m sr)\n\u001b[0;32m    157\u001b[0m     end_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(end_time \u001b[38;5;241m*\u001b[39m sr)\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:190\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Final cleanup for dtype and contiguity\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mono:\n\u001b[1;32m--> 190\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mto_mono\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     y \u001b[38;5;241m=\u001b[39m resample(y, orig_sr\u001b[38;5;241m=\u001b[39msr_native, target_sr\u001b[38;5;241m=\u001b[39msr, res_type\u001b[38;5;241m=\u001b[39mres_type)\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\librosa\\core\\audio.py:508\u001b[0m, in \u001b[0;36mto_mono\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    505\u001b[0m util\u001b[38;5;241m.\u001b[39mvalid_audio(y)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 508\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3902\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3904\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _methods\u001b[38;5;241m.\u001b[39m_mean(a, axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   3905\u001b[0m                       out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Desktop\\Python\\Audio Signal Processing\\.venv\\lib\\site-packages\\numpy\\_core\\_methods.py:136\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    133\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    134\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "\n",
    "def play_second_phase_clusters(\n",
    "    carva_csv: str,\n",
    "    master_csv: str,\n",
    "    sr: int = 44100\n",
    "):\n",
    "    \"\"\"\n",
    "    Play back motifs grouped by second-phase clustering from your carva CSV.\n",
    "    Uses StartFrame/EndFrame and Index to map back to real audio.\n",
    "\n",
    "    Args:\n",
    "        carva_csv: Path to carva CSV with 'Index', 'AudioPath', 'StartFrame', 'EndFrame', 'Second Labels'.\n",
    "        master_csv: Path to Master CSV with Time column.\n",
    "        sr: Desired sampling rate for playback.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    carva_df = pd.read_csv(carva_csv)\n",
    "    master_df = pd.read_csv(master_csv)\n",
    "\n",
    "    # Find unique clusters\n",
    "    clusters = sorted(carva_df['Second Labels'].dropna().unique())\n",
    "\n",
    "    for cluster_id in clusters:\n",
    "        print(f\"\\n=== Playing Cluster {cluster_id} ===\")\n",
    "        cluster_rows = carva_df[carva_df['Second Labels'] == cluster_id]\n",
    "\n",
    "        for _, row in cluster_rows.iterrows():\n",
    "            audio_path = row['AudioPath']\n",
    "            index = row['Index']\n",
    "            start_idx = int(row['StartFrame'])\n",
    "            end_idx = int(row['EndFrame'])\n",
    "\n",
    "            # Get real time from Master CSV for this song\n",
    "            spec_time = master_df[master_df['Index'] == index]['Time'].values\n",
    "\n",
    "            # Protect against index overflow\n",
    "            start_time = spec_time[start_idx] if start_idx < len(spec_time) else 0\n",
    "            end_time = spec_time[end_idx] if end_idx < len(spec_time) else spec_time[-1]\n",
    "\n",
    "            # Load audio\n",
    "            audio, _ = librosa.load(audio_path, sr=sr)\n",
    "\n",
    "            start_sample = int(start_time * sr)\n",
    "            end_sample = int(end_time * sr)\n",
    "\n",
    "            display(ipd.Audio(audio[start_sample:end_sample], rate=sr))\n",
    "\n",
    "        print(\"-----------------------------\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import ast\n",
    "import re\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def clean_np_float_list(seg_str):\n",
    "    \"\"\"\n",
    "    Convert a stringified list with np.float64(...) entries into a proper list of floats.\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'np\\.float64\\(([^)]+)\\)', r'\\1', seg_str)\n",
    "    return np.array(ast.literal_eval(cleaned), dtype=float)\n",
    "\n",
    "def play_specific_second_phase_cluster(\n",
    "    carva_csv: str,\n",
    "    master_csv: str,\n",
    "    cluster_number: int,\n",
    "    carnatic_frequencies: dict,\n",
    "    sr: int = 44100\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot interpolated frequency segments (overlapping from x=0) of a specific cluster, \n",
    "    showing extrema (peaks & valleys), then play the audio segments.\n",
    "    \"\"\"\n",
    "    carva_df = pd.read_csv(carva_csv)\n",
    "    master_df = pd.read_csv(master_csv)\n",
    "\n",
    "    cluster_rows = carva_df[carva_df['Second Labels'] == cluster_number]\n",
    "\n",
    "    if cluster_rows.empty:\n",
    "        print(f\"⚠️ No entries found for cluster {cluster_number}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n🎼 Plotting interpolated segments (overlapping) for Cluster {cluster_number}...\")\n",
    "\n",
    "    # Plot setup\n",
    "    plt.style.use('dark_background')\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    bars = list(carnatic_frequencies.values())\n",
    "    all_freqs = []\n",
    "\n",
    "    for _, row in cluster_rows.iterrows():\n",
    "        seg_str = row.get('Interpolated_SegmentList', None)\n",
    "        if pd.isna(seg_str):\n",
    "            continue\n",
    "        try:\n",
    "            segment = clean_np_float_list(seg_str)\n",
    "            x = np.arange(len(segment))\n",
    "            plt.plot(x, segment, alpha=0.6, linewidth=1)\n",
    "\n",
    "            # Plot extrema\n",
    "            peaks, _ = find_peaks(segment)\n",
    "            valleys, _ = find_peaks(-segment)\n",
    "            plt.plot(x[peaks], segment[peaks], \"o\", color=\"cyan\", markersize=4)\n",
    "            plt.plot(x[valleys], segment[valleys], \"o\", color=\"cyan\", markersize=4)\n",
    "\n",
    "            all_freqs.extend(segment)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping segment due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Carnatic swara bars\n",
    "    if all_freqs:\n",
    "        min_freq = np.min(all_freqs)\n",
    "        max_freq = np.max(all_freqs)\n",
    "        newbars = [i for i in bars if min_freq <= i <= max_freq]\n",
    "\n",
    "        for freq in newbars:\n",
    "            note = get_closest_note(freq, carnatic_frequencies)\n",
    "            plt.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "            plt.text(0, freq, note, color='orange', fontsize=9, verticalalignment='bottom')\n",
    "\n",
    "    plt.title(f\"Overlapping Interpolated Frequency Plots — Cluster {cluster_number}\")\n",
    "    plt.xlabel(\"Frame Index\")\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Playback\n",
    "    print(f\"\\n🎧 Playing Cluster {cluster_number} ===\")\n",
    "    for _, row in cluster_rows.iterrows():\n",
    "        audio_path = row['AudioPath']\n",
    "        index = row['Index']\n",
    "        start_idx = int(row['StartFrame'])\n",
    "        end_idx = int(row['EndFrame'])\n",
    "        swara = row['Swara'] if 'Swara' in row and pd.notna(row['Swara']) else \"Not labeled\"\n",
    "\n",
    "        print(f\"\\n📄 AudioPath: {audio_path}\")\n",
    "        print(f\"🎵 Swara: {swara}\")\n",
    "\n",
    "        spec_time = master_df[master_df['Index'] == index]['Time'].values\n",
    "        start_time = spec_time[start_idx] if start_idx < len(spec_time) else 0\n",
    "        end_time   = spec_time[end_idx] if end_idx < len(spec_time) else spec_time[-1]\n",
    "\n",
    "        try:\n",
    "            audio, _ = librosa.load(audio_path, sr=sr)\n",
    "            start_sample = int(start_time * sr)\n",
    "            end_sample = int(end_time * sr)\n",
    "            display(ipd.Audio(audio[start_sample:end_sample], rate=sr))\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not load audio: {e}\")\n",
    "\n",
    "    print(\"\\n-----------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "carnatic_ratios = {\n",
    "    'sa': 0.5*1.0,    # Tonic (Sa)\n",
    "    'ri1': 0.5*16/15, # Ri1\n",
    "    'ri2': 0.5*9/8,  # Ri2\n",
    "    'ga1': 0.5*6/5,  # Ga1\n",
    "    'ga2': 0.5*5/4, # Ga2\n",
    "    'ma1': 0.5*4/3, # Ma1\n",
    "    'ma2': 0.5*45/32,   # Ma2\n",
    "    'pa': 0.5*3/2,    # Pa\n",
    "    'da1': 0.5*8/5, # Dha1\n",
    "    'da2': 0.5*5/3, # Dha2\n",
    "    'ni1': 0.5*16/9, # Ni1\n",
    "    'ni2': 0.5*15/8,   # Ni2\n",
    "\n",
    "    'Sa': 1.0,    # Tonic (Sa)\n",
    "    'Ri1': 16/15, # Ri1\n",
    "    'Ri2': 9/8,  # Ri2\n",
    "    'Ga1': 6/5,  # Ga1\n",
    "    'Ga2': 5/4, # Ga2\n",
    "    'Ma1': 4/3, # Ma1\n",
    "    'Ma2': 45/32,   # Ma2\n",
    "    'Pa': 3/2,    # Pa\n",
    "    'Da1': 8/5, # Dha1\n",
    "    'Da2': 5/3, # Dha2\n",
    "    'Ni1': 16/9, # Ni1\n",
    "    'Ni2': 15/8,   # Ni2\n",
    "\n",
    "    'SA': 2.0,   # Octave higher (Sa)\n",
    "    'RI1': 2*16/15, # Ri1\n",
    "    'RI2': 2*9/8,  # Ri2\n",
    "    'GA1': 2*6/5,  # Ga1\n",
    "    'GA2': 2*5/4, # Ga2\n",
    "    'MA1': 2*4/3, # Ma1\n",
    "    'MA2': 2*45/32,   # Ma2\n",
    "    'PA': 2*3/2,    # Pa\n",
    "    'DA1': 2*8/5, # Dha1\n",
    "    'DA2': 2*5/3, # Dha2\n",
    "    'NI1': 2*16/9, # Ni1\n",
    "    'NI2': 2*15/8,   \n",
    "}\n",
    "\n",
    "play_specific_second_phase_cluster(\n",
    "    carnatic_frequencies=carnatic_ratios,\n",
    "    carva_csv=\"carva_Mayamalavagowlai.csv\",\n",
    "    master_csv=\"Master_Crepe_Mayamalavagowlai.csv\",\n",
    "    cluster_number=1,\n",
    "    sr=44100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Labeled 3 rows in cluster 14 as 'Ni2 Da1 Pa'.\n"
     ]
    }
   ],
   "source": [
    "def label_swara_for_cluster(\n",
    "    carva_csv: str,\n",
    "    cluster_number: int,\n",
    "    swara_label: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds or updates a column 'Swara' in the carva CSV file.\n",
    "    For all rows where 'Second Labels' == cluster_number, the value is set to swara_label.\n",
    "\n",
    "    Args:\n",
    "        carva_csv: Path to the carva CSV.\n",
    "        cluster_number: The cluster number to label.\n",
    "        swara_label: The string label to assign (e.g., 'S', 'R2', 'G3').\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(carva_csv)\n",
    "\n",
    "    # Create the 'Swara' column if it doesn't exist\n",
    "    if 'Swara' not in df.columns:\n",
    "        df['Swara'] = \"\"\n",
    "\n",
    "    # Apply the swara label to matching cluster rows\n",
    "    match_count = (df['Second Labels'] == cluster_number).sum()\n",
    "    if match_count == 0:\n",
    "        print(f\"⚠️ No rows found for cluster {cluster_number}. Nothing updated.\")\n",
    "    else:\n",
    "        df.loc[df['Second Labels'] == cluster_number, 'Swara'] = swara_label\n",
    "        df.to_csv(carva_csv, index=False)\n",
    "        print(f\"✅ Labeled {match_count} rows in cluster {cluster_number} as '{swara_label}'.\")\n",
    "\n",
    "\n",
    "label_swara_for_cluster(\n",
    "    carva_csv=\"carva_Mayamalavagowlai.csv\",\n",
    "    cluster_number=14,   # The cluster you want to label\n",
    "    swara_label=\"Ni2 Da1 Pa\"    # The swara label to apply\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
